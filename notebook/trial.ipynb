{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b5dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- IMPORTS & ENV -----------------------------------------\n",
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_classic.retrievers.contextual_compression import (\n",
    "    ContextualCompressionRetriever,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "qdrant_url = os.environ.get(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.environ.get(\"QDRANT_API_KEY\")\n",
    "cohere_api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "COLLECTION_NAME = \"compliance_docs\"\n",
    "MODEL_NAME = \"openai/gpt-oss-120b\"\n",
    "TOP_K = 6\n",
    "TOP_N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "174c2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PYDANTIC SCHEMA ----------------------------------------\n",
    "class CitedSource(BaseModel):\n",
    "    document_name: str = Field(description=\"Name of the source document\")\n",
    "    page_number: Optional[int] = Field(description=\"Page number in the document\")\n",
    "    section: Optional[str] = Field(\n",
    "        description=\"Section or article reference if mentioned e.g. Section 4.2 \"\n",
    "    )\n",
    "\n",
    "\n",
    "class ComplianceAnswer(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"The compliance answer based strictly on the provided context\"\n",
    "    )\n",
    "    found_in_docs: bool = Field(\n",
    "        description=\"True if the answer was found in the documents, False if not\"\n",
    "    )\n",
    "    sources: list[CitedSource] = Field(\n",
    "        description=\"List of sources that support the answer\"\n",
    "    )\n",
    "    confidence: str = Field(\n",
    "        description=\"How confident the answer is: high, medium, or low\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ff3469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 74 pages\n",
      "Sample: NIGERIA DATA PROTECTION REGULATION 2019...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- LOAD DOCUMENTS -----------------------------------------\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../documents/\",\n",
    "    loader_cls=PyMuPDFLoader,\n",
    "    show_progress=True,\n",
    ")\n",
    "doc = loader.load()\n",
    "print(f\"Loaded {len(doc)} pages\")\n",
    "print(f\"Sample: {doc[0].page_content[:100]}...\")\n",
    "\n",
    "\n",
    "# ---- CLEAN DOCUMENTS ----------------------------------------\n",
    "for d in doc:\n",
    "    d.page_content = re.sub(\n",
    "        r\"[ \\t]+\",\n",
    "        \" \",\n",
    "        re.sub(r\"\\n{3,}\", \"\\n\\n\", re.sub(r\"\\r\\n?\", \"\\n\", d.page_content)),\n",
    "    ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0b7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 75 chunks\n"
     ]
    }
   ],
   "source": [
    "# ---- CHUNK DOCUMENTS ----------------------------------------\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4\",\n",
    "    chunk_size=900,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\n",
    "        \"\\nPART \",\n",
    "        \"\\nPart \",\n",
    "        \"\\nCHAPTER \",\n",
    "        \"\\nChapter \",\n",
    "        \"\\nSECTION \",\n",
    "        \"\\nSection \",\n",
    "        \"\\nArticle \",\n",
    "        \"\\nARTICLE \",\n",
    "        \"\\nSCHEDULE \",\n",
    "        \"\\nSchedule \",\n",
    "        \"\\n\\n\",\n",
    "        \"\\n(\",\n",
    "        \"\\n(a)\",\n",
    "        \"\\n(i)\",\n",
    "        \"\\n• \",\n",
    "        \"\\n- \",\n",
    "        \"\\n\",\n",
    "        \". \",\n",
    "        \" \",\n",
    "        \"\",\n",
    "    ],\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = splitter.split_documents(doc)\n",
    "print(f\"Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5bbd7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting into Qdrant...\n",
      "Ingestion complete\n"
     ]
    }
   ],
   "source": [
    "dense_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", api_key=openai_api_key\n",
    ")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "print(\"Ingesting into Qdrant...\")\n",
    "qdrant_store = QdrantVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=dense_embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    ")\n",
    "print(\"Ingestion complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673c83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- RETRIEVER + COHERE RERANKER ----------------------------\n",
    "base_retriever = qdrant_store.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "\n",
    "reranker = CohereRerank(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model=\"rerank-english-v3.0\",\n",
    "    top_n=TOP_N,\n",
    ")\n",
    "\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker, base_retriever=base_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c282a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LLM SETUP + STRUCTURED OUTPUT --------------------------\n",
    "llm = ChatGroq(model=MODEL_NAME, api_key=groq_api_key, temperature=0)\n",
    "\n",
    "# Binds the Pydantic schema to the LLM.\n",
    "structured_llm = llm.with_structured_output(ComplianceAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f531cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- SQLITE CHAT HISTORY SETUP ------------------------------\n",
    "\n",
    "conn = sqlite3.connect(\"chat_history.db\")\n",
    "conn.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS messages (\n",
    "        id        INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        session   TEXT    NOT NULL,\n",
    "        role      TEXT    NOT NULL,\n",
    "        content   TEXT    NOT NULL,\n",
    "        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47b83ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 messages fro history\n"
     ]
    }
   ],
   "source": [
    "# ---- LOAD HISTORY FROM SQLITE -------------------------------\n",
    "session_id = \"session_1\"\n",
    "conn = sqlite3.connect(\"chat_history.db\")\n",
    "rows = conn.execute(\n",
    "    \"SELECT role, content FROM messages WHERE session = ? ORDER BY id\", (session_id,)\n",
    ").fetchall()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "for role, content in rows:\n",
    "    if role == \"human\":\n",
    "        chat_history.append(HumanMessage(content=content))\n",
    "    else:\n",
    "        chat_history.append(AIMessage(content=content))\n",
    "\n",
    "print(f\"Loaded {len(chat_history)} messages fro history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21059f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: what is survelliance?\n"
     ]
    }
   ],
   "source": [
    "# ---- USER QUESTION ----------\n",
    "question = \"what is survelliance?\"\n",
    "\n",
    "CONTEXTUALIZE_PROMPT = \"\"\"Given the chat history and the latest user question, \\\n",
    "rewrite the question as a fully standalone question that can be understood \\\n",
    "without the chat history. Do NOT answer it, only rewrite it. \\\n",
    "If it is already standalone, return it as is.\"\"\"\n",
    "\n",
    "if chat_history:\n",
    "    contextualize_messages = (\n",
    "        [SystemMessage(content=CONTEXTUALIZE_PROMPT)]\n",
    "        + chat_history\n",
    "        + [HumanMessage(content=question)]\n",
    "    )\n",
    "    standalone_question = llm.invoke(contextualize_messages).content\n",
    "else:\n",
    "    standalone_question = question\n",
    "\n",
    "print(f\"Standalone question: {standalone_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb346c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 chunks after reranking\n"
     ]
    }
   ],
   "source": [
    "# ---- RETRIEVE + RERANK -------\n",
    "retrieved_docs = retriever.invoke(standalone_question)\n",
    "print(f\"Retrieved {len(retrieved_docs)} chunks after reranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "274c75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FORMAT CONTEXT ----------------------\n",
    "context_parts = []\n",
    "for i, d in enumerate(retrieved_docs, 1):\n",
    "    source = d.metadata.get(\"source\", \"Unknown\")\n",
    "    page = d.metadata.get(\"page\", \"?\")\n",
    "    context_parts.append(f\"[{i}] Source: {source} | Page: {page}\\n{d.page_content}\")\n",
    "\n",
    "context = \"\\n\\n---\\n\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c28c7a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1] Source: ..\\\\documents\\\\NDPR Audit Template.pdf | Page: 27\\n27 | P a g e \\n \\ni. \\nA description of the circumstances of the loss or unauthorized access or \\ndisclosure \\nii. \\nThe date or time period during which the loss or unauthorized access or \\ndisclosure occurred \\niii. \\nA description of the personal information involved in the loss or \\nunauthorized access or disclosure \\niv. \\nAn assessment of the risk of harm to individuals as a result of the loss or \\nunauthorized access or disclosure \\nv. \\nAn estimate of the number of individuals to whom there is a real risk of \\nsignificant harm as a result of the loss or unauthorized access or \\ndisclosure \\nvi. \\nA description of any steps the organization has taken to reduce the risk \\nof harm to individuals \\nvii. \\nA description of any steps the organization has taken to notify individuals \\nof the loss or unauthorized access or disclosure, and \\nviii. \\nThe name and contact information for a person who can answer, on \\nbehalf of the organization, the Agency’s questions about the loss of \\nunauthorized access or disclosure \\n11. \\nENFORCEMENT FRAMEWORK \\n \\n \\n \\n11.1 Forms of Enforcement\\n\\n---\\n\\n[2] Source: ..\\\\documents\\\\NDPR Audit Template.pdf | Page: 27\\n27 | P a g e \\n \\ni. \\nA description of the circumstances of the loss or unauthorized access or \\ndisclosure \\nii. \\nThe date or time period during which the loss or unauthorized access or \\ndisclosure occurred \\niii. \\nA description of the personal information involved in the loss or \\nunauthorized access or disclosure \\niv. \\nAn assessment of the risk of harm to individuals as a result of the loss or \\nunauthorized access or disclosure \\nv. \\nAn estimate of the number of individuals to whom there is a real risk of \\nsignificant harm as a result of the loss or unauthorized access or \\ndisclosure \\nvi. \\nA description of any steps the organization has taken to reduce the risk \\nof harm to individuals \\nvii. \\nA description of any steps the organization has taken to notify individuals \\nof the loss or unauthorized access or disclosure, and \\nviii. \\nThe name and contact information for a person who can answer, on \\nbehalf of the organization, the Agency’s questions about the loss of \\nunauthorized access or disclosure \\n11. \\nENFORCEMENT FRAMEWORK \\n \\n \\n \\n11.1 Forms of Enforcement\\n\\n---\\n\\n[3] Source: ..\\\\documents\\\\NDPR Audit Template.pdf | Page: 28\\n28 | P a g e \\n \\n11.1.1 Surveillance \\nSurveillance refers to specific, deliberate monitoring carried out to identify \\nbreach of the NDPR. This routine activity arises out of the understanding that \\noperators or parties are legally obliged to perform specific tasks in order to \\ncomply with provisions of NDPR, particularly as it affects Data Subjects. Such \\nControllers may be in deliberate or unconscious breach of the Regulation. \\nSurveillance will aid NITDA to identify breaches of regulatory instruments or co-\\nopt other stakeholders to identify and report breaches to the Agency. \\n11.1.2 Complaint Filings \\nAny person who believes a party is not complying with any of the provisions of \\nthe Regulation may file a complaint with NITDA. Such complaints must meet the \\nfollowing requirements: \\na. \\na complaint must be filed in writing, either on paper or electronically. \\nb. \\na complaint must name the Data Controller or Administrator that is the \\nsubject of the complaint and describe the acts or omissions believed to be in \\nviolation of the applicable provision(s). \\nc. \\nNITDA may prescribe additional procedures for the filing of complaints, \\nas well as the place and manner of filing. \\n11.1.3 Investigations \\nNITDA will investigate any complaint filed against a Data Controller or \\nAdministrator when a preliminary review of the facts indicates a possible \\nviolation of the provision(s) of the NDPR. NITDA may by its officers or through \\ndesignated DPCO, investigate any complaint filed by third parties and may also \\ndo so based on a special audit check or “spot check”. Investigation may include \\na review of the policies, procedures, or practices of the concerned entity and of \\nthe circumstances regarding any alleged violation. At the time of the initial'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa3d60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Surveillance refers to specific, deliberate monitoring carried out to identify breach of the NDPR. It is a routine activity intended to ensure that operators or parties comply with the provisions of the NDPR, helping NITDA identify breaches and involve other stakeholders in reporting them.\n",
      "Found in docs: True\n",
      "Confidence: high\n",
      "Sources:\n",
      "  - ..\\documents\\NDPR Audit Template.pdf | Page 28 | Section 11.1.1 Surveillance\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a precise compliance assistant. \\\n",
    "Answer using ONLY the provided context from the compliance documents. \\\n",
    "Always cite the source document name, page number, and section if available. \\\n",
    "Set found_in_docs to False and explain that the answer was not found if the context does not support an answer. \\\n",
    "Set confidence based on how clearly the context supports the answer: high, medium, or low.\"\"\"\n",
    "\n",
    "messages = (\n",
    "    [SystemMessage(content=SYSTEM_PROMPT)]\n",
    "    + chat_history\n",
    "    + [HumanMessage(content=f\"Context:\\n{context}\\n\\nQuestion: {question}\")]\n",
    ")\n",
    "\n",
    "result = structured_llm.invoke(messages)\n",
    "\n",
    "print(f\"\\nAnswer: {result.answer}\")\n",
    "print(f\"Found in docs: {result.found_in_docs}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n",
    "print(\"Sources:\")\n",
    "for s in result.sources:\n",
    "    print(f\"  - {s.document_name} | Page {s.page_number} | Section {s.section}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to history.\n"
     ]
    }
   ],
   "source": [
    "# ---- SAVE TO SQLITE -------------\n",
    "conn = sqlite3.connect(\"chat_history.db\")\n",
    "conn.execute(\n",
    "    \"INSERT INTO messages (session, role, content) VALUES (?, ?, ?)\",\n",
    "    (session_id, \"human\", question),\n",
    ")\n",
    "conn.execute(\n",
    "    \"INSERT INTO messages (session, role, content) VALUES (?, ?, ?)\",\n",
    "    (session_id, \"ai\", result.answer),\n",
    ")\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nSaved to history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a3125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
